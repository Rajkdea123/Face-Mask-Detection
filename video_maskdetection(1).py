# -*- coding: utf-8 -*-
"""Video_MaskDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hif0APj_lN0LfV7V7G0eWMLADTtylTUV
"""

!pip install --upgrade tensorflow keras

from tensorflow.keras.preprocessing.image import load_img

#Own cnn  architecture - mask detection CNN.ipynb

# import packages
import cv2
import os
from keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

#load model # Accuracy=97.4 , validation Accuracy = 99.1 # very light model, size =5MB
model = load_model('/content/drive/MyDrive/model_last02.h5') # cnn

# model accept below hight and wi
img_width, img_hight = 200, 200

# Load the Cascade face Classifier
face_cascade = cv2.CascadeClassifier("/content/drive/MyDrive/live mask detection app/haarcascade_frontalface_default.xml")

#startt  web cam
#cap = cv2.VideoCapture(0) # for webcam
cap = cv2.VideoCapture('/content/drive/MyDrive/live mask detection app/videos/Mask - 34775.mp4') # for video

from google.colab.patches import cv2_imshow

img_count_full = 0

# Parameters for text
font = cv2.FONT_HERSHEY_SIMPLEX
org = (1, 1)
class_label = ' '
fontScale = 1
color = (255, 0, 0)
thickness = 2

# Image dimensions
img_width = 200
img_height = 200

# Start reading images and prediction
while True:
    img_count_full += 1

    # Read image from webcam
    response, color_img = cap.read()

    # If response is False, break the loop
    if not response:
        break

    # Convert to grayscale
    gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)

    # Detect faces
    faces = face_cascade.detectMultiScale(gray_img, 1.1, 6)

    # Take face, then predict class (mask or no mask), draw rectangle and text, and display image
    img_count = 0
    for (x, y, w, h) in faces:
        org = (x - 10, y - 10)
        img_count += 1
        color_face = color_img[y:y+h, x:x+w]  # Color face
        cv2.imwrite('/content/drive/MyDrive/dataset/train/with_mask/{}_{}-with-mask.jpg'.format(img_count_full, img_count), color_face)
        img = load_img('/content/drive/MyDrive/dataset/train/with_mask/{}_{}-with-mask.jpg'.format(img_count_full, img_count), target_size=(img_width, img_height))

        img = img_to_array(img) / 255
        img = np.expand_dims(img, axis=0)
        pred_prob = model.predict(img)
        pred = np.argmax(pred_prob)

        if pred == 0:
            print("User with mask - prediction = ", pred_prob[0][0])
            class_label = "Mask"
            color = (255, 0, 0)
        else:
            print('User not wearing mask - probability = ', pred_prob[0][1])
            class_label = "No Mask"
            color = (0, 255, 0)

        cv2.rectangle(color_img, (x, y), (x + w, y + h), (0, 0, 255), 3)
        # Using cv2.putText() method
        cv2.putText(color_img, class_label, org, font, fontScale, color, thickness, cv2.LINE_AA)

    # Display image
    cv2_imshow(color_img)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the VideoCapture object
cap.release()
cv2.destroyAllWindows()